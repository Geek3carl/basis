{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 将历史对话直接保存成记忆"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConversationBufferMemory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 示例化ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# 添加一些历史聊天内容\n",
    "memory.save_context(\n",
    "    {'input': '你是谁？'},\n",
    "    {'output': '我是一个人工智能'}\n",
    ")\n",
    "\n",
    "# 查看记忆组件中的聊天历史\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "chain.run('你是谁？')\n",
    "print(chain.run('你能为我做什么？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConversationBufferWindowMemory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# 实例化ConversationBufferWindowMemory，并设置保留最近两次交互的历史消息\n",
    "memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
    "\n",
    "# 添加历史内容\n",
    "memory.save_context(\n",
    "    {'input': '你是谁？'}, {'output': '我是一个人工智能'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '你能帮我做什么？'}, {'output': '我可以帮你解答问题'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '我喜欢吃什么水果？'}, {'output': '我不知道'}\n",
    ")\n",
    "\n",
    "# 获取历史消息\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "chain.run('你是谁？')\n",
    "chain.run('你能为我做什么？')\n",
    "chain.run('我喜欢吃什么水果？')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConversationTokenBufferMemory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "# 实例化ConversationTokenBufferMemory\n",
    "# 并设置所用大模型和max_token_limit的值\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=ChatOpenAI(),\n",
    "    max_token_limit=30\n",
    ")\n",
    "\n",
    "# 添加历史内容\n",
    "memory.save_context(\n",
    "    {'input': '你是谁？'}, {'output': '我是一个人工智能'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '你能帮我做什么？'}, {'output': '我可以帮你解答问题'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '我喜欢吃什么水果？'}, {'output': '我不知道'}\n",
    ")\n",
    "\n",
    "# 获取历史消息\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120\n",
    ")\n",
    "\n",
    "chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "chain.run('你是谁？')\n",
    "chain.run('你能为我做什么？')\n",
    "chain.run('我喜欢吃什么水果？')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 将历史对话总结后保存成记忆"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConversationSummaryMemory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "# 实例化 ConversationSummaryMemory\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=ChatOpenAI(),\n",
    "    # 如果你希望在实例化时就添加一些历史消息作为总结，则可以设置这个值\n",
    "    buffer=''\n",
    ")\n",
    "\n",
    "# 添加历史内容\n",
    "memory.save_context(\n",
    "    {'input': '你是谁？'}, {'output': '我是一个人工智能'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '你能帮我做什么？'}, {'output': '我可以帮你解答问题'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '我喜欢吃什么水果？'}, {'output': '我不知道'}\n",
    ")\n",
    "\n",
    "# 获取历史消息\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "print(chain.run('你是谁？'))\n",
    "print(chain.run('你能为我做什么？'))\n",
    "chain.run('我喜欢吃什么水果？')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConversationSummaryBufferMemory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm, max_token_limit=20,\n",
    ")\n",
    "#\n",
    "chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "print(chain.run('请记住我喜欢的水果是葡萄'))\n",
    "print(chain.run('你能为我做什么？'))\n",
    "print(chain.run('我喜欢吃什么水果？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# 实例化ConversationSummaryBufferMemory\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=ChatOpenAI()\n",
    ")\n",
    "\n",
    "# 添加历史内容\n",
    "memory.save_context(\n",
    "    {'input': '你能帮我做什么？'}, {'output': '我可以帮你解答问题'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '我喜欢吃什么水果？'}, {'output': '我不知道'}\n",
    ")\n",
    "\n",
    "# 使用save_context保存的message都被存储在memory.chat_memory中\n",
    "messages = memory.chat_memory.messages\n",
    "# 之前的总结内容\n",
    "previous_summary = '人类问我，我是谁？我回答他们说我是人工智能。'\n",
    "\n",
    "# 根据之前总结的内容和新的messages预测新的总结\n",
    "res = memory.predict_new_summary(messages, previous_summary)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 通过向量数据库将历史数据保存成记忆"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "# 初始化向量数据库\n",
    "db = Chroma(\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory='./chroma_memory/'\n",
    ")\n",
    "# 转成retriever对象\n",
    "retriever = db.as_retriever(search_kwargs={'k': 1})\n",
    "\n",
    "# 初始化内存\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# 添加历史内容\n",
    "memory.save_context(\n",
    "    {'input': '我最喜欢吃的水果是葡萄'}, {'output': '好的'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '你能帮我做什么？'}, {'output': '我可以帮你解答问题'}\n",
    ")\n",
    "print(memory.load_memory_variables({'prompt': '我喜欢吃什么水果？'}))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# 初始化向量数据库\n",
    "db = Chroma(\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory='./chroma_memory/'\n",
    ")\n",
    "# 转成retriever对象\n",
    "retriever = db.as_retriever(search_kwargs={'k': 1})\n",
    "\n",
    "# 初始化内存\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "chain.run('请记住我最喜欢的水果是葡萄')\n",
    "chain.run('你能为我做什么？')\n",
    "print(chain.run('我喜欢吃什么水果？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 多Memory组合"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import (\n",
    "    ConversationBufferWindowMemory,\n",
    "    CombinedMemory,\n",
    "    ConversationSummaryMemory,\n",
    ")\n",
    "\n",
    "# 创建用于记忆最近5条的记忆组件\n",
    "conv_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history', input_key='input'\n",
    ")\n",
    "\n",
    "# 创建用于总结聊天的记忆组件\n",
    "# 因为两个内存组件都需要对输入的内容进行记忆，所以这两个组件的input_key都设置为input\n",
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=ChatOpenAI(), input_key='input', memory_key='history'\n",
    ")\n",
    "\n",
    "# 使用CombinedMemory对象组合内存组件\n",
    "memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
    "\n",
    "_DEFAULT_TEMPLATE = '''The following is a friendly conversation\n",
    "between a human and an AI. The AI is talkative and provides\n",
    "lots of specific details from its context. If the AI does\n",
    "not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "{history}\n",
    "Current conversation:\n",
    "{chat_history}\n",
    "Human: {input}\n",
    "AI:'''\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['history', 'input', 'chat_history'],\n",
    "    template=_DEFAULT_TEMPLATE,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True,\n",
    "    memory=memory, prompt=prompt\n",
    ")\n",
    "conversation.run('你是谁？')\n",
    "conversation.run('你可以帮我干什么？')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 实体记忆及实体关系记忆"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 通过记录实体进行记忆"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "input = {'input': '小明和小张在踢足球，小红在坐着休息'}\n",
    "\n",
    "# 将输入的内容提取为entity\n",
    "memory.load_memory_variables(input)\n",
    "\n",
    "memory.save_context(\n",
    "    input,\n",
    "    {'output': '现在的比分是多少？'}\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({'input': '小明在做什么？'}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    ")\n",
    "\n",
    "chain.run('小明在和小张踢足球')\n",
    "print(chain.memory.entity_store.store)\n",
    "\n",
    "chain.run('小红过来看他们踢足球')\n",
    "print(chain.memory.entity_store.store)\n",
    "\n",
    "chain.run('小李和小刚加入了他们，一起来踢足球')\n",
    "print(chain.memory.entity_store.store)\n",
    "\n",
    "chain.run('小陈跑来和他们说，要上课了')\n",
    "print(chain.memory.entity_store.store)\n",
    "\n",
    "print('-----------question--------------')\n",
    "print(chain.run('小李刚才在干什么？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 通过知识图谱进行记忆"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between\n",
    "a human and an AI. The AI is talkative and provides lots of specific\n",
    "details from its context.\n",
    "If the AI does not know the answer to a question,\n",
    "it truthfully says it does not know. The AI ONLY uses\n",
    "information contained in the \"Relevant Information\"\n",
    "section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationKGMemory(llm=llm)\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = ConversationChain(\n",
    "    llm=llm, verbose=True, prompt=prompt, memory=memory\n",
    ")\n",
    "\n",
    "chain.run(\"小明和小红是邻居\")\n",
    "chain.run(\"小明和小张是邻居\")\n",
    "print(chain.run(\"小红和小张是什么关系\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 在使用LCEL的链中添加内存组件"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema.runnable import (\n",
    "    RunnablePassthrough,\n",
    "    RunnableLambda\n",
    ")\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are a helpful chatbot'),\n",
    "        # 用于生成模板时填充history内容\n",
    "        MessagesPlaceholder(variable_name='history'),\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    # 以Message对象形式返回\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "        # 首先通过memory.load_memory_variables方法获取存储的history字典\n",
    "        # 然后使用itemgetter获取history键对应的值\n",
    "        # 最后将这个值作为传入内容的字典的history键的值\n",
    "            history=RunnableLambda(\n",
    "                memory.load_memory_variables\n",
    "            ) | itemgetter('history')\n",
    "        )\n",
    "        | prompt\n",
    "        | model\n",
    ")\n",
    "\n",
    "inputs = {'input': '你是谁？'}\n",
    "response = chain.invoke(inputs)\n",
    "\n",
    "# 将提问和回答存入内存组件\n",
    "memory.save_context(inputs, {\"output\": response.content})\n",
    "\n",
    "print(chain.invoke({'input': '我刚才问了什么？'}))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 自定义记忆组件"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory.chat_memory import BaseChatMemory\n",
    "from langchain.schema.messages import get_buffer_string\n",
    "\n",
    "\n",
    "class CustomBufferMemory(BaseChatMemory):\n",
    "    human_prefix = 'Human'\n",
    "    ai_prefix = 'AI'\n",
    "    memory_key = 'history'\n",
    "\n",
    "    @property\n",
    "    def memory_variables(self):\n",
    "        \"\"\"用户返回这个记忆组件中，记录的信息字典的key的值\"\"\"\n",
    "        return [self.memory_key]\n",
    "\n",
    "    @property\n",
    "    def buffer(self):\n",
    "        # 如果return_messages是True，则返回Message对象列表\n",
    "        if self.return_messages:\n",
    "            return self.chat_memory.messages\n",
    "\n",
    "        # 否则就返回通过Message对象列表转换后的字符串\n",
    "        return get_buffer_string(\n",
    "            self.chat_memory.messages,\n",
    "            human_prefix=self.human_prefix,\n",
    "            ai_prefix=self.ai_prefix,\n",
    "        )\n",
    "\n",
    "    def load_memory_variables(self, inputs):\n",
    "        \"\"\"用于返回历史数据\"\"\"\n",
    "        return {self.memory_key: self.buffer}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    human_prefix='人类',\n",
    "    ai_prefix='机器人'\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {'input': '你能帮我做什么？'}, {'output': '我可以帮你解答问题'}\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': '我喜欢吃什么水果？'}, {'output': '我不知道'}\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

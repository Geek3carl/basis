{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Agent初探"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain.agents import (\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name='gpt-3.5-turbo-instruct',\n",
    "    temperature=0.6\n",
    ")\n",
    "tools = load_tools(['ddg-search', 'llm-math'], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools, llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    max_iterations=5,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=False\n",
    ")\n",
    "print(agent.invoke('OpenAI开发者大会召开的年份除以4，最后得到的数字是多少？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.load.dump import dumps\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")\n",
    "response = agent('OpenAI开发者大会召开的年份除以4，最后得到的数字是多少？')\n",
    "print(response[\"intermediate_steps\"])\n",
    "\n",
    "# 使用LangChain提供的dumps方法可以将字典转换成JSON字符串\n",
    "print(dumps(response[\"intermediate_steps\"], pretty=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agent类型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chat ReAct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain.agents import (\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name='gpt-3.5-turbo-instruct',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "chat_llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools(['ddg-search', 'llm-math'], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools, chat_llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "print(agent.invoke('OpenAI开发者大会召开的年份除以4，最后得到的数字是多少？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ReAct Document Store"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain_community.docstore.wikipedia import Wikipedia\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "\n",
    "# 初始化文档存储\n",
    "docstore = DocstoreExplorer(Wikipedia())\n",
    "\n",
    "# 初始化Search和Lookup工具\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Search',\n",
    "        func=docstore.search,\n",
    "        description='useful for when you need to ask with search',\n",
    "    ),\n",
    "    Tool(\n",
    "        name='Lookup',\n",
    "        func=docstore.lookup,\n",
    "        description='useful for when you need to ask with lookup',\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools, llm,\n",
    "    agent=AgentType.REACT_DOCSTORE,\n",
    "    verbose=True\n",
    ")\n",
    "print(agent.invoke('秦朝建立是在什么时间？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conversational"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import Tool, AgentType, initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "\n",
    "# 使用GoogleSerperAPIWrapper需要先到Serper官网注册登录\n",
    "# 然后设置以下环境变量为你的API key\n",
    "os.environ['SERPER_API_KEY'] = 'xxxxxx'\n",
    "\n",
    "search =  GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='search',\n",
    "        func=search.run,\n",
    "        description='用于搜索当前事件'\n",
    "    )\n",
    "]\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o',temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools, llm,\n",
    "    # CHAT_CONVERSATIONAL_REACT_DESCRIPTION用于聊天类型模型\n",
    "    # CONVERSATIONAL_REACT_DESCRIPTION用于LLM补全模型\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "agent.invoke(input='小张今年25岁。')\n",
    "print(agent.invoke('秦朝建立是哪一年？秦朝建立时间加上小张的年龄等于多少？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OpenAI Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word):\n",
    "    \"\"\"计算单词的长度\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "tools = [get_word_length]\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(agent.invoke(\n",
    "    'How many letters are there in Hangzhou and Beijing?'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Self-Ask With Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-4o',\n",
    "    temperature=0\n",
    ")\n",
    "search = GoogleSerperAPIWrapper()\n",
    "\n",
    "# SELF_ASK_WITH_SEARCH类型的Agent只能设置一个工具\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Intermediate Answer',\n",
    "        func=search.run,\n",
    "        description='useful for when you need to ask with search',\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm,\n",
    "    agent=AgentType.SELF_ASK_WITH_SEARCH,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(agent.invoke('2023年微软CEO出生于哪个国家？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Structured Tool Chat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 在非Jupyter Notebooks环境下可以不用导入nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.agent_toolkits.playwright.toolkit import (\n",
    "    PlayWrightBrowserToolkit)\n",
    "from langchain_community.tools.playwright.utils import (\n",
    "    create_async_playwright_browser)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 初始化工具集\n",
    "async_browser = create_async_playwright_browser()\n",
    "toolkit = PlayWrightBrowserToolkit.from_browser(\n",
    "    async_browser=async_browser)\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5)\n",
    "agent_chain = initialize_agent(\n",
    "    tools, llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "response = await agent_chain.ainvoke(\n",
    "    'movie.douban.com/subject/1292063/ 网页的标题是什么？')\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat_history = MessagesPlaceholder(\n",
    "    variable_name='chat_history'\n",
    ")\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\n",
    "        'memory_prompts': [chat_history],\n",
    "        'input_variables': ['input', 'agent_scratchpad', 'chat_history']\n",
    "    },\n",
    "    memory=memory,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OpenAI Assistant"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "\n",
    "interpreter_assistant = OpenAIAssistantRunnable.create_assistant(\n",
    "    name='langchain assistant',\n",
    "    instructions='You are a personal math tutor. '\n",
    "                 'Write and run code to answer math questions.',\n",
    "    tools=[\n",
    "        {'type': 'code_interpreter'},\n",
    "        {'type': 'retrieval'},\n",
    "        DuckDuckGoSearchRun()\n",
    "    ],\n",
    "    model='gpt-4o',\n",
    "    as_agent=True\n",
    ")\n",
    "output = interpreter_assistant.invoke(\n",
    "    {'content': \"What's 10 - 4 raised to the 2.7\"}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "\n",
    "agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name='langchain assistant',\n",
    "    instructions='You are a personal math tutor. '\n",
    "                 'Write and run code to answer math questions. '\n",
    "                 'You can also search the internet.',\n",
    "    model='gpt-4o',\n",
    "    tools=[{'type': 'code_interpreter'}],\n",
    "    as_agent=True,\n",
    ")\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=[DuckDuckGoSearchRun()]\n",
    ")\n",
    "output = agent_executor.invoke(\n",
    "    {'content': \"What's the weather in SF today divided by 2.7\"}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 自定义Tool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用Tool对象"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.pydantic_v1 import BaseModel, Field, root_validator\n",
    "\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "search_tool = Tool.from_function(\n",
    "    func=search.run,\n",
    "    name='Search',\n",
    "    description='useful for when you need to answer '\n",
    "                'questions about current events',\n",
    ")\n",
    "\n",
    "class WordInput(BaseModel):\n",
    "    word: str = Field(description='Word to calculate length')\n",
    "\n",
    "    @root_validator\n",
    "    def validate_parameter(cls, values):\n",
    "        \"\"\"用于对传递进来的函数的参数进行验证\"\"\"\n",
    "        word = values['word']\n",
    "        try:\n",
    "            # 如果可以转换成数字，那么它就是非文字字符\n",
    "            int(word)\n",
    "            raise ValueError(\n",
    "                'The word parameter type must be a literal character')\n",
    "        except:\n",
    "            return values\n",
    "\n",
    "def get_word_length(word):\n",
    "    return len(word)\n",
    "\n",
    "word_tool = Tool(\n",
    "        name='get_word_length',\n",
    "        description='Calculate the length of a word',\n",
    "        func=get_word_length,\n",
    "        args_schema=WordInput\n",
    "    )\n",
    "\n",
    "\n",
    "tools = [search_tool, word_tool]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 继承BaseTool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = 'custom_search'\n",
    "    description = ('useful for when you need to '\n",
    "                   'answer questions about current events')\n",
    "\n",
    "    def _run(\n",
    "            self, query: str,\n",
    "            run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"调用工具\"\"\"\n",
    "        return search.run(query)\n",
    "\n",
    "    async def _arun(\n",
    "            self, query: str,\n",
    "            run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"异步调用工具\"\"\"\n",
    "        raise NotImplementedError('custom_search does not support async')\n",
    "\n",
    "\n",
    "tools = [CustomSearchTool()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用Tool装饰器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word):\n",
    "    \"\"\"计算单词长度\"\"\"\n",
    "    return len(word)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class WordInput(BaseModel):\n",
    "    word: str = Field(description='Word to calculate length')\n",
    "\n",
    "@tool(\"word_handler\", return_direct=True, args_schema=WordInput)\n",
    "def get_word_length(word):\n",
    "    \"\"\"计算单词长度\"\"\"\n",
    "    return len(word)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Structured Tool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "def plus(a: float, b: float):\n",
    "    \"\"\"计算两个数的和\"\"\"\n",
    "    return a + b\n",
    "\n",
    "plus_tool = StructuredTool.from_function(plus)\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    [plus_tool], llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "print(agent.invoke('6加10等于多少？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = 'custom_search'\n",
    "    description = ('useful for when you need to '\n",
    "                   'answer questions about current events')\n",
    "\n",
    "    def _run(\n",
    "            self,\n",
    "            query: str,\n",
    "            engine: str = 'google',\n",
    "            gl: str = 'us',\n",
    "            hl: str = 'en',\n",
    "            run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"调用工具\"\"\"\n",
    "        search_wrapper = SerpAPIWrapper(\n",
    "            params={'engine': engine, 'gl': gl, 'hl': hl})\n",
    "        return search_wrapper.run(query)\n",
    "\n",
    "    async def _arun(\n",
    "            self,\n",
    "            query: str,\n",
    "            engine: str = 'google',\n",
    "            gl: str = 'us',\n",
    "            hl: str = 'en',\n",
    "            run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"异步调用工具\"\"\"\n",
    "        raise NotImplementedError('custom_search does not support async')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 异常处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools.base import ToolException\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "\n",
    "def _handle_error(error: ToolException) -> str:\n",
    "    return f'工具执行过程中发生以下错误：{error.args[0]}'\n",
    "\n",
    "\n",
    "def search_tool1(s: str):\n",
    "    raise ToolException('The search tool1 is not available.')\n",
    "\n",
    "\n",
    "def search_tool2(s: str):\n",
    "    raise ToolException('The search tool2 is not available.')\n",
    "\n",
    "\n",
    "def search_tool3(s: str):\n",
    "    raise ToolException('The search tool3 is not available.')\n",
    "\n",
    "\n",
    "description = ('useful for when you need to '\n",
    "               'answer questions about current events')\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search_tool1,\n",
    "        name='Search_tool1',\n",
    "        description=description,\n",
    "        handle_tool_error=True,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=search_tool2,\n",
    "        name='Search_tool2',\n",
    "        description=description,\n",
    "        handle_tool_error=_handle_error,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=search_tool2,\n",
    "        name='Search_tool3',\n",
    "        description=description,\n",
    "        handle_tool_error='工具3出错啦',\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    ChatOpenAI(temperature=0),\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "agent.invoke('\"晴天\"的作者是谁？')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 人工校验及输入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 默认人工校验"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_community.tools import ShellTool\n",
    "from langchain_community.callbacks import HumanApprovalCallbackHandler\n",
    "\n",
    "tool = ShellTool(callbacks=[HumanApprovalCallbackHandler()])\n",
    "tool.run('ls')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义用户审批"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain_community.callbacks import HumanApprovalCallbackHandler\n",
    "\n",
    "\n",
    "def _should_check(serialized_obj: dict) -> bool:\n",
    "    # 当工具名称为terminal时，需要进行审批\n",
    "    return serialized_obj.get('name') == 'terminal'\n",
    "\n",
    "\n",
    "def _approve(_input: str) -> bool:\n",
    "    if _input == 'echo \"Hello World\"':\n",
    "        return True\n",
    "    msg = (\n",
    "        '是否批准执行以下输入？'\n",
    "        '回复Y或者yes为批准，回复其他内容则视为不批准。'\n",
    "    )\n",
    "    msg += '\\n\\n' + _input + '\\n'\n",
    "    resp = input(msg)\n",
    "    return resp.lower() in ('yes', 'y')\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    HumanApprovalCallbackHandler(\n",
    "        should_check=_should_check,\n",
    "        approve=_approve\n",
    "    )]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "tools = load_tools(['wikipedia', 'llm-math', 'terminal'], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools, llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    ")\n",
    "\n",
    "res = agent.invoke('秦朝统一六国是哪一年？', callbacks=callbacks)\n",
    "print(res)\n",
    "res = agent.invoke('请列出当前目录下的文件', callbacks=callbacks)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 人工输入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-4o',\n",
    "    temperature=0\n",
    ")\n",
    "tools = load_tools(['human', 'llm-math'], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    # 如果出现结果解析错误，可以将handle_parsing_errors设置为True\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True\n",
    ")\n",
    "print(agent.invoke(\n",
    "    '请先让用户一次性输入两个值（用逗号隔开），然后对这两个值进行加法运算'\n",
    "))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agent实际应用"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 结合向量存储使用Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "\n",
    "loader = WebBaseLoader('https://****.ruff.**/docs/faq/')[　请参考链接8-2。]\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "texts = text_splitter.split_documents(loader.load())\n",
    "\n",
    "ruff_db = Chroma.from_documents(\n",
    "    texts,\n",
    "    OpenAIEmbeddings(),\n",
    "    collection_name='ruff'\n",
    ")\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    chain_type='stuff',\n",
    "    retriever=ruff_db.as_retriever()\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Ruff QA System',\n",
    "        func=chain.run,\n",
    "        description='当你需要回答关于ruff（一个Python linter）的问题时，它很有用。'\n",
    "        # 如果希望直接返回chain的结果，可以设置如下参数：\n",
    "        # return_direct=True\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, ChatOpenAI(temperature=0),\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "print(agent.invoke('什么是ruff？'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fake Agent（虚构代理）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain_community.llms import FakeListLLM\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "\n",
    "responses = [\n",
    "    'Action: Python REPL\\nAction Input: print(2 + 2)',\n",
    "    'Final Answer: 4'\n",
    "]\n",
    "\n",
    "llm = FakeListLLM(responses=responses)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "print(agent.invoke('whats 2 + 2'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Any, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import (\n",
    "    Tool, AgentExecutor, BaseSingleActionAgent\n",
    ")\n",
    "\n",
    "\n",
    "class FakeAgent(BaseSingleActionAgent):\n",
    "    \"\"\"自定义虚构Agent \"\"\"\n",
    "\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"input\"]\n",
    "\n",
    "    def plan(\n",
    "            self,\n",
    "            intermediate_steps: List[Tuple[AgentAction, str]],\n",
    "            **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        # 如果之前搜索到了，就直接返回搜索到的答案\n",
    "        # 当整个Agent执行完时，需要返回AgentFinish对象\n",
    "        if intermediate_steps:\n",
    "            return AgentFinish(\n",
    "                return_values={'output': intermediate_steps[-1][-1]},\n",
    "                log=''\n",
    "            )\n",
    "        # 当Agent还未执行完时，需要返回AgentAction对象，\n",
    "        # 并指定下一个要执行的工具\n",
    "        return AgentAction(\n",
    "            tool='Search',\n",
    "            tool_input=kwargs['input'],\n",
    "            log=''\n",
    "        )\n",
    "\n",
    "    async def aplan(\n",
    "            self,\n",
    "            intermediate_steps: List[Tuple[AgentAction, str]],\n",
    "            **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        if intermediate_steps:\n",
    "            return AgentFinish(\n",
    "                return_values={'output': intermediate_steps[-1][-1]},\n",
    "                log=''\n",
    "            )\n",
    "        return AgentAction(\n",
    "            tool='Search',\n",
    "            tool_input=kwargs['input'],\n",
    "            log=''\n",
    "        )\n",
    "\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Search',\n",
    "        func=search.run,\n",
    "        description='useful for when you need to '\n",
    "                    'answer questions about current events'\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = FakeAgent()\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")\n",
    "print(agent_executor.invoke('秦朝统一六国是哪一年？'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义LLM Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Union\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.schema import (\n",
    "    AgentAction, AgentFinish, OutputParserException\n",
    ")\n",
    "from langchain.agents import (\n",
    "    Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    ")\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Search',\n",
    "        func=search.run,\n",
    "        description='useful for when you need to '\n",
    "                    'answer questions about current events'\n",
    "    )\n",
    "]\n",
    "\n",
    "template = '''Answer the following questions as best you can,\n",
    "but speaking as a pirate might speak.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer.\n",
    "Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}'''\n",
    "\n",
    "\n",
    "# 自定义PromptTemplate\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # 获取中间步骤的信息列表，并按特定的格式将其格式化成字符串\n",
    "        intermediate_steps = kwargs.pop('intermediate_steps')\n",
    "        thoughts = ''\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f'\\nObservation: {observation}\\nThought: '\n",
    "\n",
    "        # 将格式化好的内容存入agent_scratchpad对应的值中\n",
    "        kwargs['agent_scratchpad'] = thoughts\n",
    "\n",
    "        # 将工具列表按照“名字:描述”的格式转换成字符串，\n",
    "        # 并将其存入tools对应的值中\n",
    "        kwargs['tools'] = '\\n'.join([\n",
    "            f\"{tool.name}: {tool.description}\" for tool in self.tools\n",
    "        ])\n",
    "        # 创建工具名称列表字符串，并将其存入tool_names对应的值中\n",
    "        kwargs['tool_names'] = ', '.join(\n",
    "            [tool.name for tool in self.tools]\n",
    "        )\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    input_variables=['input', 'intermediate_steps']\n",
    ")\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # 如果LLM的输出中有“Final Answer”，则表示当前任务已执行完毕\n",
    "        # 需要返回AgentFinish\n",
    "        if 'Final Answer:' in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\n",
    "                    'output': llm_output.split('Final Answer:')[-1].strip()\n",
    "                },\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # 解析动作和动作输入\n",
    "        reg = (r'Action\\s*\\d*\\s*:(.*?)\\n'\n",
    "               r'Action\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)')\n",
    "        match = re.search(reg, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise OutputParserException(\n",
    "                f'Could not parse LLM output: `{llm_output}`')\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "\n",
    "        # 返回后续需要执行的AgentAction，并设置要执行的工具和工具输入\n",
    "        return AgentAction(\n",
    "            tool=action,\n",
    "            tool_input=action_input.strip(' ').strip('\"'),\n",
    "            log=llm_output\n",
    "        )\n",
    "\n",
    "\n",
    "output_parser = CustomOutputParser()\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    # 这个停止标志是Prompt中用来表示观测（Observation）开始的那个标志。\n",
    "    # 如果没有设定这样的标志，则LLM可能会“幻想”出一个观测结果\n",
    "    stop=['\\nObservation:'],\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "agent_executor.invoke('秦朝统一六国是哪一年？')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "template_with_history = '''Answer the following questions as best you can,\n",
    "but speaking as a pirate might speak.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer.\n",
    "Use lots of \"Arg\"s\n",
    "\n",
    "Previous conversation history:\n",
    "{chat_history}\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}'''\n",
    "\n",
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=tools,\n",
    "    input_variables=['input', 'intermediate_steps', 'chat_history']\n",
    ")\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt_with_history)\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=['\\nObservation:'],\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "\n",
    "memory=ConversationBufferWindowMemory(\n",
    "    k=2, memory_key='chat_history'\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "agent_executor.invoke('秦朝统一六国是哪一年？')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义MRKL Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Search',\n",
    "        func=search.run,\n",
    "        description='useful for when you need to '\n",
    "                    'answer questions about current events',\n",
    "    )\n",
    "]\n",
    "\n",
    "prefix = '''Answer the following questions as best you can,\n",
    "but speaking as a pirate might speak.\n",
    "You have access to the following tools:\n",
    "'''\n",
    "\n",
    "suffix = '''Begin! Remember to speak as a pirate\n",
    "when giving your final answer. Use lots of \"Args\"\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "'''\n",
    "\n",
    "# 创建prompt\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=['input', 'agent_scratchpad']\n",
    ")\n",
    "\n",
    "# 实例化LLMChain\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prompt=prompt\n",
    ")\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "# 实例化agent\n",
    "agent = ZeroShotAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "\n",
    "# 实例化agent执行器\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "agent_executor.invoke('秦朝统一六国是哪一年？')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义具有工具检索功能的Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union, Callable\n",
    "\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    "    Tool,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "# 创建搜索工具\n",
    "search = GoogleSerperAPIWrapper()\n",
    "search_tool = Tool(\n",
    "    name='Search',\n",
    "    func=search.run,\n",
    "    description='useful for when you need to '\n",
    "                'answer questions about current events',\n",
    ")\n",
    "\n",
    "# 创建虚构工具\n",
    "def fake_func(inp):\n",
    "    return 'foo'\n",
    "\n",
    "fake_tools = [\n",
    "    Tool(\n",
    "        name=f'foo-{i}',\n",
    "        func=fake_func,\n",
    "        description=f'a silly function that you can use to '\n",
    "                    f'get more information about the number {i}',\n",
    "    )\n",
    "    for i in range(99)\n",
    "]\n",
    "\n",
    "ALL_TOOLS = [search_tool] + fake_tools\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=t.description, metadata={'index': i})\n",
    "    for i, t in enumerate(ALL_TOOLS)\n",
    "]\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    docs,\n",
    "    OpenAIEmbeddings(),\n",
    "    collection_name='tools'\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "def get_tools(query):\n",
    "    \"\"\"通过查询获取最适合的工具\"\"\"\n",
    "    _docs = retriever.get_relevant_documents(query)\n",
    "    return [ALL_TOOLS[d.metadata['index']] for d in _docs]\n",
    "\n",
    "\n",
    "template = '''Answer the following questions as best you can,\n",
    "but speaking as a pirate might speak.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer.\n",
    "Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}'''\n",
    "\n",
    "\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str\n",
    "    # 可用的工具列表\n",
    "    tools_getter: Callable\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # 获取中间步骤的信息列表，并按特定的格式将其格式化成字符串\n",
    "        intermediate_steps = kwargs.pop('intermediate_steps')\n",
    "        thoughts = ''\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f'\\nObservation: {observation}\\nThought: '\n",
    "\n",
    "        # 将格式化好的内容存入agent_scratchpad对应的值中\n",
    "        kwargs['agent_scratchpad'] = thoughts\n",
    "\n",
    "        # 这里和LLM Agent示例中的内容有所不同\n",
    "        # 这里会先执行tools_getter对应的get_tools方法，\n",
    "        # 即通过输入的内容获取最匹配的几个工具\n",
    "        # 而不是像LLM Agent示例那样使用全部的工具\n",
    "        tools = self.tools_getter(kwargs['input'])\n",
    "        # 将工具列表按照“名字:描述”的格式转换成字符串，并将其存入tools对应的值中\n",
    "        kwargs['tools'] = '\\n'.join(\n",
    "            [f'{tool.name}: {tool.description}' for tool in tools]\n",
    "        )\n",
    "        # 创建工具名称列表字符串，并将其存入tool_names对应的值中\n",
    "        kwargs['tool_names'] = ', '.join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools_getter=get_tools,\n",
    "    input_variables=['input', 'intermediate_steps'],\n",
    ")\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # 如果LLM的输出中有“Final Answer”，则表示当前任务已执行完毕\n",
    "        # 需要返回AgentFinish\n",
    "        if 'Final Answer:' in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\n",
    "                    'output': llm_output.split('Final Answer:')[-1].strip()\n",
    "                },\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # 解析动作和动作输入\n",
    "        reg = (r'Action\\s*\\d*\\s*:(.*?)\\n'\n",
    "               r'Action\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)')\n",
    "        match = re.search(reg, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise OutputParserException(\n",
    "                f'Could not parse LLM output: `{llm_output}`')\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "\n",
    "        # 返回后续需要执行的AgentAction，并设置要执行的工具和工具输入\n",
    "        return AgentAction(\n",
    "            tool=action,\n",
    "            tool_input=action_input.strip(' ').strip('\"'),\n",
    "            log=llm_output\n",
    "        )\n",
    "\n",
    "output_parser = CustomOutputParser()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-4-1106-preview',\n",
    "    temperature=0\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "_input = '秦朝统一六国的时间'\n",
    "\n",
    "# 先获取可以获取的与问题相关的工具列表\n",
    "tools = get_tools(_input)\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=['\\nObservation:'],\n",
    "    allowed_tools=tool_names,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "agent_executor.invoke(_input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Auto-GPT Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_experimental.autonomous_agents import AutoGPT\n",
    "from langchain_community.tools import ReadFileTool\n",
    "from langchain_community.tools import WriteFileTool\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='search',\n",
    "        func=search.run,\n",
    "        description='useful for when you need to '\n",
    "                    'answer questions about current events. '\n",
    "                    'You should ask targeted questions',\n",
    "    ),\n",
    "    WriteFileTool(),\n",
    "    ReadFileTool(),\n",
    "]\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(\n",
    "    persist_directory='./chroma',\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name='Tom',\n",
    "    ai_role='Assistant',\n",
    "    tools=tools,\n",
    "    llm=ChatOpenAI(\n",
    "        model_name='gpt-4o',\n",
    "        temperature=0\n",
    "    ),\n",
    "    memory=vectorstore.as_retriever(),\n",
    ")\n",
    "\n",
    "# 打开详情模式\n",
    "agent.chain.verbose = True\n",
    "\n",
    "# 生成一个关于今天杭州天气的中文报告\n",
    "agent.run([\n",
    "    'Please help me write a Chinese report on '\n",
    "    'the weather in Hangzhou today, in which the '\n",
    "    'temperature unit needs to be in Celsius and '\n",
    "    'saved as \"hangzhou_weather.txt\"'\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LangGraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 示例"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import functools\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "@tool('web_search')\n",
    "def web_search(query):\n",
    "    \"\"\"通过Google SERP API进行互联网搜索查询\"\"\"\n",
    "    search = SerpAPIWrapper()\n",
    "    return search.run(query)\n",
    "\n",
    "\n",
    "@tool('red_book_writer')\n",
    "def write_red_book(content):\n",
    "    \"\"\"根据一段内容，写一个小红书文案\"\"\"\n",
    "    chat = ChatOpenAI(model='gpt-4-turbo-preview')\n",
    "    system_msg = SystemMessage(\n",
    "        content='你的任务是以小红书博主的文章结构，以我给出的主题，写一篇推荐帖。'\n",
    "                '你的回答应包括使用表情符号来增加趣味和互动，'\n",
    "                '以及与每个段落相匹配的图片。'\n",
    "                '请以一个引人入胜的介绍开始，为你的推荐帖设置基调。'\n",
    "                '然后，提供至少3个与主题相关的段落，突出它们的特点和吸引力。'\n",
    "                '在你的写作中使用表情符号，使文案更加引人入胜和有趣。'\n",
    "    )\n",
    "    messages = [\n",
    "        system_msg,\n",
    "        HumanMessage(content=content),\n",
    "    ]\n",
    "    response = chat(messages)\n",
    "    return response.content\n",
    "\n",
    "system_prompt = (\n",
    "    'You are a supervisor tasked with managing a conversation between the'\n",
    "    ' following workers:  {members}. Given the following user request,'\n",
    "    ' respond with the worker to act next. Each worker will perform a'\n",
    "    ' task and respond with their results and status. When finished,'\n",
    "    ' respond with FINISH.'\n",
    ")\n",
    "\n",
    "members = ['Search_Engine', 'Red_Book_Writer']\n",
    "options = ['FINISH'] + members\n",
    "\n",
    "\n",
    "# 使用OpenAI的函数调用，可以更方便地输出一个结构化的内容\n",
    "func_structure = {\n",
    "    'name': 'route',\n",
    "    'description': 'Select the next role.',\n",
    "    'parameters': {\n",
    "        'title': 'routeSchema',\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'next': {\n",
    "                'title': 'Next',\n",
    "                'anyOf': [\n",
    "                    {'enum': options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        'required': ['next'],\n",
    "    },\n",
    "}\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', system_prompt),\n",
    "        MessagesPlaceholder(variable_name='messages'),\n",
    "        (\n",
    "            'system',\n",
    "            'Given the conversation above, who should act next?'\n",
    "            ' Or should we FINISH? Select one of: {options}',\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=', '.join(members))\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-turbo-preview')\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[func_structure], function_call='route')\n",
    "    | JsonOutputFunctionsParser()\n",
    ")\n",
    "\n",
    "def create_agent(llm, tools, system_prompt):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                'system',\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name='messages'),\n",
    "            MessagesPlaceholder(variable_name='agent_scratchpad'),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {'messages': [HumanMessage(content=result['output'], name=name)]}\n",
    "\n",
    "\n",
    "search_engine_agent = create_agent(\n",
    "    llm,\n",
    "    [web_search],\n",
    "    '你是一个网络搜索引擎'\n",
    ")\n",
    "search_engine_node = functools.partial(\n",
    "    agent_node,\n",
    "    agent=search_engine_agent,\n",
    "    name='Search_Engine'\n",
    ")\n",
    "\n",
    "red_book_agent = create_agent(\n",
    "    llm,\n",
    "    [write_red_book],\n",
    "    '你的主要职责是根据给定的内容编写小红书文案。'\n",
    ")\n",
    "red_book_node = functools.partial(\n",
    "    agent_node,\n",
    "    agent=red_book_agent,\n",
    "    name='Red_Book_Writer'\n",
    ")\n",
    "\n",
    "# 状态对象存储了两个字段：\n",
    "# messages用于保存上游处理完的信息\n",
    "# next用于记录要执行哪个下游节点\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node('Search_Engine', search_engine_node)\n",
    "workflow.add_node('Red_Book_Writer', red_book_node)\n",
    "workflow.add_node('supervisor', supervisor_chain)\n",
    "\n",
    "# 这里实际上添加的代码逻辑是，执行完对应的节点再回到supervisor节点\n",
    "for member in members:\n",
    "    workflow.add_edge(member, 'supervisor')\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map['FINISH'] = END\n",
    "workflow.add_conditional_edges(\n",
    "    'supervisor',\n",
    "    lambda x: x['next'],\n",
    "    conditional_map\n",
    ")\n",
    "\n",
    "# 设置起始节点\n",
    "workflow.set_entry_point('supervisor')\n",
    "graph = workflow.compile()\n",
    "\n",
    "for s in graph.stream({\n",
    "    'messages': [\n",
    "        HumanMessage(\n",
    "            content='请先搜索OpenAI的Sora，并根据搜索结果写一篇小红书文案'\n",
    "        )\n",
    "    ]\n",
    "}):\n",
    "    if '__end__' not in s:\n",
    "        print(s)\n",
    "        print('----')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
